Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10

Traceback (most recent call last):
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 99, in <module>
    main(args)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 28, in main
    algorithm = algorithm_class(args).cuda()
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in <lambda>
    return self._apply(lambda t: t.cuda(device))
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 99, in <module>
    main(args)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 42, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/alg/algs/diversify.py", line 133, in update_a
    all_x = minibatches[0].cuda().float()
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Using device: cpu
Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 104, in <module>
    main(args)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 47, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/alg/algs/diversify.py", line 133, in update_a
    all_x = minibatches[0].cuda().float()
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Using device: cpu
Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
Traceback (most recent call last):
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 104, in <module>
    main(args)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 47, in main
    loss_result_dict = algorithm.update_a(data, opta)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/alg/algs/diversify.py", line 133, in update_a
    all_x = minibatches[0].cuda().float()
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Using device: cpu
Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                0.5756678581    
1                0.6259881854    
2                0.5635536909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                0.8492186069     0.8297655582     0.0194530655    
1                0.8277046680     0.8249357343     0.0027689151    
2                0.8454068303     0.8445154428     0.0008914031    
Counter({7: 977, 3: 817, 5: 560, 0: 538, 2: 346, 9: 321, 8: 283, 6: 126, 1: 118, 4: 58})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
Traceback (most recent call last):
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 104, in <module>
    main(args)
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/train.py", line 82, in main
    results['train_acc'] = modelopera.accuracy(
  File "/Users/jessekroll/Desktop/Bachelor Thesis 24/Repos for TSCAR models/robustlearn/diversify/alg/modelopera.py", line 21, in accuracy
    x = data[0].cuda().float()
  File "/opt/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
Using device: cpu
Environment:
	Python: 3.10.9
	PyTorch: 2.2.2
	Torchvision: 0.17.2
	CUDA: None
	CUDNN: None
	NumPy: 1.23.5
	PIL: 11.2.1
==========================================
algorithm:diversify
alpha:1.0
alpha1:1.0
batch_size:32
beta1:0.5
bottleneck:256
checkpoint_freq:100
classifier:linear
data_file:
dataset:emg
data_dir:./data/
dis_hidden:256
gpu_id:0
layer:bn
lam:0.0
latent_domain_num:10
local_epoch:3
lr:0.01
lr_decay1:1.0
lr_decay2:1.0
max_epoch:50
model_size:median
N_WORKERS:4
old:False
seed:0
task:cross_people
test_envs:[0]
output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01
weight_decay:0.0005
steps_per_epoch:10000000000
select_position:{'emg': [0]}
select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}
hz_list:{'emg': 1000}
act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}
num_classes:6
input_shape:(8, 1, 200)
grid_size:10


========ROUND 0========
====Feature update====
epoch            class_loss      
0                0.5756678581    
1                0.6259881854    
2                0.5635536909    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                0.8492186069     0.8297655582     0.0194530655    
1                0.8277046680     0.8249357343     0.0027689151    
2                0.8454068303     0.8445154428     0.0008914031    
Counter({7: 977, 3: 817, 5: 560, 0: 538, 2: 346, 9: 321, 8: 283, 6: 126, 1: 118, 4: 58})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4472295344     1.0330340862     1.4802635908     0.8185328185     0.8028985507     0.6690140845     36.6970307827   
1                0.6664998531     1.0399984121     1.7064982653     0.7427606178     0.7053140097     0.6408450704     73.2747309208   
2                0.4601829350     1.0334823132     1.4936652184     0.8535231660     0.8222222222     0.6942488263     115.1086938381  

========ROUND 1========
====Feature update====
epoch            class_loss      
0                1.0824121237    
1                0.9726998210    
2                0.9270147681    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2075026035     0.6502495408     0.5572531223    
1                1.3080737591     0.6456081867     0.6624655724    
2                1.0592412949     0.6314960718     0.4277452826    
Counter({7: 980, 3: 571, 5: 518, 0: 482, 9: 422, 2: 376, 8: 332, 6: 181, 1: 141, 4: 141})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4325017929     0.9514296055     1.3839313984     0.8243243243     0.8019323671     0.6308685446     36.0932879448   
1                0.4259944260     1.0308794975     1.4568738937     0.8108108108     0.7787439614     0.6825117371     75.0841972828   
2                0.7537286282     0.9539915919     1.7077202797     0.8337355212     0.8009661836     0.6707746479     132.8680262566  

========ROUND 2========
====Feature update====
epoch            class_loss      
0                1.0318729877    
1                0.7447180748    
2                0.6556133032    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3698587418     0.8537269235     0.5161318183    
1                1.1709142923     0.7683494091     0.4025649130    
2                1.1141878366     0.6820943952     0.4320934117    
Counter({7: 1084, 5: 496, 8: 430, 9: 363, 3: 344, 0: 337, 4: 300, 2: 298, 6: 290, 1: 202})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4813335240     1.3514268398     1.8327603340     0.7893339768     0.7536231884     0.6167840376     41.2005362511   
1                0.3664611876     0.9153430462     1.2818042040     0.8933397683     0.8560386473     0.7065727700     80.9902372360   
2                0.3929047883     1.0403822660     1.4332870245     0.8139478764     0.7700483092     0.6349765258     122.0497591496  

========ROUND 3========
====Feature update====
epoch            class_loss      
0                0.7277817726    
1                0.8761048317    
2                0.7835348248    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1878782511     0.7568948269     0.4309834540    
1                1.3344397545     0.6856502891     0.6487894058    
2                1.6972115040     0.9611631036     0.7360484600    
Counter({8: 820, 7: 649, 9: 417, 0: 395, 4: 338, 1: 329, 3: 310, 6: 306, 2: 306, 5: 274})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.4718632102     1.1008391380     1.5727024078     0.8774131274     0.8270531401     0.6654929577     41.3458511829   
1                0.3281053305     0.9021638036     1.2302691936     0.8347007722     0.8019323671     0.6349765258     78.1984541416   
2                0.3479808271     1.1278562546     1.4758371115     0.9092664093     0.8492753623     0.6795774648     119.0955462456  

========ROUND 4========
====Feature update====
epoch            class_loss      
0                0.8512866497    
1                0.8946444392    
2                0.5905737877    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.7330858707     0.9479058385     0.7851800323    
1                1.3614468575     0.8187113404     0.5427354574    
2                1.4832578897     0.9035948515     0.5796630383    
Counter({7: 842, 8: 436, 1: 436, 2: 391, 9: 367, 0: 360, 4: 355, 5: 330, 6: 319, 3: 308})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2283669114     0.9856520891     1.2140190601     0.8889961390     0.8241545894     0.6842723005     2457.8214950562 
1                0.3549667597     0.8734762073     1.2284429073     0.9133687259     0.8415458937     0.6713615023     9302.9988470078 
2                0.3896827996     1.1729809046     1.5626636744     0.8723455598     0.8038647343     0.6584507042     14629.323203086 

========ROUND 5========
====Feature update====
epoch            class_loss      
0                0.7782524824    
1                0.7450374961    
2                0.6786193252    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0556814671     0.6413628459     0.4143185616    
1                1.2699098587     0.8216789365     0.4482308626    
2                1.4175052643     0.9264519215     0.4910533726    
Counter({7: 892, 8: 433, 9: 429, 2: 400, 1: 388, 0: 366, 4: 357, 5: 298, 6: 297, 3: 284})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3621581793     0.8917191029     1.2538772821     0.8564189189     0.7797101449     0.6214788732     7331.7283768654 
1                0.2667793036     1.0155256987     1.2823050022     0.8735521236     0.7835748792     0.6590375587     14661.373973131 
2                0.2854247391     1.1925458908     1.4779706001     0.9181949807     0.8086956522     0.6801643192     14823.112007856 

========ROUND 6========
====Feature update====
epoch            class_loss      
0                0.6733774543    
1                0.4395110607    
2                0.5350024700    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3257044554     0.9099602103     0.4157442749    
1                1.3586889505     0.7426038980     0.6160850525    
2                1.2027891874     0.7792947292     0.4234944582    
Counter({7: 907, 1: 414, 9: 404, 8: 374, 2: 369, 3: 358, 4: 347, 5: 343, 0: 314, 6: 314})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2616216540     1.1121977568     1.3738193512     0.9061293436     0.8260869565     0.6889671362     40.5814881325   
1                0.3081730306     1.1267049313     1.4348779917     0.9041988417     0.8328502415     0.6631455399     86.9714031219   
2                0.2348069102     0.8437530994     1.0785599947     0.9167471042     0.8212560386     0.6825117371     126.3783180714  

========ROUND 7========
====Feature update====
epoch            class_loss      
0                0.5949254632    
1                0.6916036010    
2                0.6504703164    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0873011351     0.7673881054     0.3199130297    
1                1.4748127460     0.9151310325     0.5596817136    
2                1.3486998081     0.9346538186     0.4140459299    
Counter({7: 923, 1: 432, 2: 387, 9: 375, 8: 354, 3: 346, 4: 344, 0: 341, 5: 329, 6: 313})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2438071519     0.9339220524     1.1777292490     0.9179536680     0.8338164251     0.6854460094     42.4021997452   
1                0.4206168950     1.4384033680     1.8590202332     0.9213320463     0.8019323671     0.6889671362     78.0128178596   
2                0.2354944050     1.0183912516     1.2538856268     0.9107142857     0.8115942029     0.6789906103     112.9002230167  

========ROUND 8========
====Feature update====
epoch            class_loss      
0                0.5762090087    
1                0.4371447563    
2                0.4097047150    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                0.9611754417     0.6186128855     0.3425625563    
1                1.1654717922     0.7308007479     0.4346710443    
2                1.0289092064     0.7502055764     0.2787035704    
Counter({7: 876, 1: 436, 9: 416, 8: 393, 2: 366, 3: 351, 5: 348, 6: 340, 0: 315, 4: 303})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3296976388     0.9121857882     1.2418833971     0.9172297297     0.8289855072     0.6737089202     33.2264871597   
1                0.3465927839     1.0534577370     1.4000505209     0.9341216216     0.8260869565     0.6649061033     70.2773780823   
2                0.2926498055     0.9403100610     1.2329598665     0.9365347490     0.8289855072     0.6619718310     105.0767490864  

========ROUND 9========
====Feature update====
epoch            class_loss      
0                0.4379311204    
1                0.4714607000    
2                0.4475528896    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0066374540     0.7150065899     0.2916308641    
1                1.0395452976     0.7978270054     0.2417183518    
2                2.1937901974     1.2482185364     0.9455716610    
Counter({7: 857, 1: 465, 9: 414, 5: 402, 8: 400, 3: 378, 2: 327, 4: 318, 0: 301, 6: 282})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1831980497     1.0473064184     1.2305045128     0.9524613900     0.8386473430     0.6719483568     35.2256598473   
1                0.1652421951     0.9254822135     1.0907244682     0.9302606178     0.8270531401     0.6355633803     70.5895948410   
2                0.2691390216     1.2495341301     1.5186731815     0.9005791506     0.7961352657     0.6244131455     109.2225489616  

========ROUND 10========
====Feature update====
epoch            class_loss      
0                0.4620093703    
1                0.3874133527    
2                0.2728123367    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3857617378     0.9696605206     0.4161012173    
1                1.0474199057     0.7499845028     0.2974354029    
2                1.1739573479     0.8517990112     0.3221583366    
Counter({7: 903, 1: 449, 8: 394, 5: 380, 3: 373, 2: 352, 4: 350, 9: 343, 0: 319, 6: 281})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1940133572     0.9043728709     1.0983862877     0.9232625483     0.8077294686     0.6126760563     34.4156448841   
1                0.1722590327     1.2078089714     1.3800680637     0.7642374517     0.6473429952     0.5000000000     69.3466908932   
2                0.2398656458     1.0180020332     1.2578676939     0.9266409266     0.8077294686     0.6338028169     104.9337921143  

========ROUND 11========
====Feature update====
epoch            class_loss      
0                0.5701665878    
1                0.4677844644    
2                0.3304175735    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2869942188     0.9639357328     0.3230585158    
1                1.0588796139     0.7647047043     0.2941749096    
2                1.2940106392     0.9089837670     0.3850269020    
Counter({7: 931, 1: 486, 8: 399, 5: 373, 4: 362, 3: 358, 9: 328, 2: 328, 0: 291, 6: 288})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2330311388     0.9195378423     1.1525689363     0.9432915058     0.8260869565     0.6555164319     32.5416162014   
1                0.1700585485     0.9964472651     1.1665058136     0.9133687259     0.7864734300     0.6238262911     65.5835490227   
2                0.1999420673     1.1362484694     1.3361905813     0.9505308880     0.8135265700     0.6496478873     98.8357782364   

========ROUND 12========
====Feature update====
epoch            class_loss      
0                0.4139314890    
1                0.4254001975    
2                0.2734830678    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1786421537     0.8687649965     0.3098771572    
1                1.0172307491     0.7331649065     0.2840657830    
2                1.0714868307     0.8549239635     0.2165629119    
Counter({7: 855, 1: 509, 4: 418, 8: 394, 2: 379, 3: 358, 5: 329, 0: 316, 9: 306, 6: 280})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1496783346     0.9311025143     1.0807808638     0.9184362934     0.7835748792     0.6208920188     34.1817526817   
1                0.2152361274     1.1988433599     1.4140794277     0.9652509653     0.8202898551     0.6701877934     68.4576158524   
2                0.2308929563     1.0322073698     1.2631003857     0.9674227799     0.8202898551     0.6555164319     101.3615648746  

========ROUND 13========
====Feature update====
epoch            class_loss      
0                0.3526945412    
1                0.2960361540    
2                0.3433867693    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0876084566     0.7711136341     0.3164948523    
1                1.2268412113     0.8919406533     0.3349006176    
2                1.1348277330     0.8011672497     0.3336604536    
Counter({7: 844, 1: 544, 4: 426, 2: 384, 3: 355, 8: 353, 5: 333, 0: 315, 9: 299, 6: 291})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1566792428     0.9281075001     1.0847867727     0.9664575290     0.8193236715     0.6566901408     33.4277219772   
1                0.1347368658     1.1415194273     1.2762563229     0.9403957529     0.7893719807     0.6502347418     66.7092032433   
2                0.2306813449     1.0778611898     1.3085424900     0.9375000000     0.7990338164     0.6402582160     98.9963881969   

========ROUND 14========
====Feature update====
epoch            class_loss      
0                0.4843088686    
1                0.5400112867    
2                0.3782069087    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2477325201     0.9207426906     0.3269898295    
1                1.1862107515     0.9372177124     0.2489930838    
2                1.1113389730     0.9022920132     0.2090469748    
Counter({7: 870, 1: 500, 4: 420, 2: 402, 8: 386, 3: 337, 5: 333, 9: 313, 0: 311, 6: 272})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1331642866     0.9912050962     1.1243693829     0.9416023166     0.7990338164     0.6379107981     42.1413612366   
1                0.1588417888     1.6297358274     1.7885775566     0.9510135135     0.7806763285     0.6373239437     85.7676830292   
2                0.2663750648     1.0584343672     1.3248094320     0.9305019305     0.7806763285     0.6214788732     128.8449740410  

========ROUND 15========
====Feature update====
epoch            class_loss      
0                0.3247760534    
1                0.3655815125    
2                0.2496202588    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1605862379     0.9317881465     0.2287980467    
1                1.0913577080     0.8616292477     0.2297284305    
2                1.1628149748     1.0003213882     0.1624935865    
Counter({7: 866, 1: 482, 2: 416, 4: 415, 8: 382, 3: 337, 5: 335, 9: 317, 0: 315, 6: 279})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1135036424     1.0364810228     1.1499847174     0.9720077220     0.8028985507     0.6449530516     42.2878248692   
1                0.0764588714     1.1010767221     1.1775355339     0.9577702703     0.7961352657     0.6561032864     84.8581819534   
2                0.1549173743     1.0228065252     1.1777238846     0.9828667954     0.8106280193     0.6555164319     124.9176449776  

========ROUND 16========
====Feature update====
epoch            class_loss      
0                0.2778588831    
1                0.2167480588    
2                0.2273961455    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0364148617     0.7419906259     0.2944242656    
1                1.3119394779     0.8838028312     0.4281366765    
2                1.0138870478     0.8417730927     0.1721139401    
Counter({7: 867, 1: 491, 4: 414, 2: 405, 8: 387, 5: 335, 3: 330, 0: 330, 9: 313, 6: 272})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1928691864     1.2364935875     1.4293627739     0.9408783784     0.7739130435     0.6566901408     45.0044348240   
1                0.1659654975     1.0741622448     1.2401278019     0.9389478764     0.7864734300     0.6285211268     1606.2219860554 
2                0.1784123629     1.4833519459     1.6617642641     0.9594594595     0.7893719807     0.6467136150     1649.0502557755 

========ROUND 17========
====Feature update====
epoch            class_loss      
0                0.5909130573    
1                0.2512265146    
2                0.1893413514    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0704703331     0.8940966725     0.1763736755    
1                1.0858353376     0.8796713352     0.2061640024    
2                0.9763573408     0.8009546399     0.1754027307    
Counter({7: 856, 1: 487, 4: 428, 2: 405, 8: 361, 5: 347, 0: 326, 3: 325, 9: 313, 6: 296})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.3961268067     1.1065704823     1.5026972294     0.9809362934     0.8183574879     0.6713615023     46.2352662086   
1                0.1917718947     1.0965954065     1.2883672714     0.9642857143     0.7874396135     0.6414319249     81.4946160316   
2                0.1300308108     0.9860165119     1.1160473824     0.9768339768     0.8154589372     0.6408450704     116.7356481552  

========ROUND 18========
====Feature update====
epoch            class_loss      
0                0.3079888523    
1                0.1880712658    
2                0.2206167430    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0398581028     0.8453587294     0.1944993436    
1                1.1800744534     0.9199677706     0.2601067126    
2                1.0842393637     0.9221920371     0.1620472819    
Counter({7: 891, 1: 475, 4: 411, 2: 408, 8: 369, 5: 348, 0: 335, 3: 328, 9: 301, 6: 278})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1721494049     1.3619718552     1.5341212749     0.9802123552     0.8106280193     0.6678403756     46.1249222755   
1                0.1589861065     1.1717563868     1.3307424784     0.9724903475     0.8125603865     0.6490610329     92.8145573139   
2                0.1523743123     1.1506789923     1.3030532598     0.9756274131     0.8096618357     0.6531690141     141.1417050362  

========ROUND 19========
====Feature update====
epoch            class_loss      
0                0.2718743086    
1                0.2536613047    
2                0.1765863597    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.0955055952     0.8277689815     0.2677366138    
1                0.8302522302     0.7448573112     0.0853949413    
2                1.3048701286     1.0241262913     0.2807438076    
Counter({7: 872, 1: 492, 4: 431, 2: 390, 8: 357, 5: 349, 0: 330, 3: 326, 6: 305, 9: 292})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2548866868     1.0945106745     1.3493974209     0.9758687259     0.7961352657     0.6285211268     40.1622829437   
1                0.0727423355     1.0128005743     1.0855429173     0.9821428571     0.8038647343     0.6537558685     82.5431580544   
2                0.1259362698     1.2528656721     1.3788019419     0.9483590734     0.7835748792     0.6244131455     127.5029358864  

========ROUND 20========
====Feature update====
epoch            class_loss      
0                0.3466405571    
1                0.2739737332    
2                0.1936668605    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1701871157     0.9117012024     0.2584859133    
1                1.2048918009     0.9907627106     0.2141290605    
2                1.2546193600     1.0822459459     0.1723734736    
Counter({7: 858, 1: 491, 4: 435, 2: 393, 8: 373, 5: 348, 0: 326, 3: 324, 6: 305, 9: 291})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1464530230     1.1010367870     1.2474898100     0.9674227799     0.7971014493     0.6678403756     41.2318401337   
1                0.1550844014     1.0684841871     1.2235685587     0.9823841699     0.8106280193     0.6590375587     95.1690609455   
2                0.1417736411     1.5096762180     1.6514499187     0.9700772201     0.7768115942     0.6291079812     144.8869600296  

========ROUND 21========
====Feature update====
epoch            class_loss      
0                0.3243029118    
1                0.1743302047    
2                0.3776383400    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2174118757     1.0166033506     0.2008085102    
1                1.2642927170     1.0081169605     0.2561757863    
2                1.1216502190     1.0109359026     0.1107142866    
Counter({7: 807, 1: 482, 4: 459, 2: 405, 8: 400, 5: 340, 3: 330, 0: 329, 6: 301, 9: 291})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1337360591     1.3003070354     1.4340430498     0.9568050193     0.7951690821     0.6343896714     57.0839531422   
1                0.0989432111     1.4592235088     1.5581667423     0.9548745174     0.7739130435     0.6279342723     112.0217792988  
2                0.2155761272     1.3337190151     1.5492951870     0.9802123552     0.7913043478     0.6267605634     168.0717711449  

========ROUND 22========
====Feature update====
epoch            class_loss      
0                0.1975028217    
1                0.2363179326    
2                0.2063820213    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1799628735     1.0121885538     0.1677743495    
1                1.1460362673     1.0149153471     0.1311209202    
2                0.8428817391     0.7448464632     0.0980352908    
Counter({7: 815, 1: 474, 4: 469, 2: 410, 8: 397, 5: 337, 3: 330, 0: 325, 6: 297, 9: 290})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1510254592     1.2699596882     1.4209851027     0.9782818533     0.8048309179     0.6484741784     53.7386701107   
1                0.0887802839     1.3134403229     1.4022206068     0.9845559846     0.7903381643     0.6326291080     105.8571608067  
2                0.1203493252     1.3814995289     1.5018488169     0.9623552124     0.7806763285     0.6285211268     157.4512019157  

========ROUND 23========
====Feature update====
epoch            class_loss      
0                0.2424456328    
1                0.1386799365    
2                0.2270548344    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2927134037     1.0750751495     0.2176382095    
1                1.0599696636     0.9276110530     0.1323586553    
2                1.1402554512     1.0092735291     0.1309819818    
Counter({7: 818, 1: 516, 4: 447, 8: 390, 2: 387, 5: 353, 3: 333, 0: 327, 6: 300, 9: 273})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1481772065     1.2333036661     1.3814809322     0.9543918919     0.7816425121     0.6244131455     56.5007050037   
1                0.0697025359     1.4777340889     1.5474365950     0.9604247104     0.7710144928     0.6320422535     113.9242091179  
2                0.1155921593     1.3401334286     1.4557255507     0.9802123552     0.7951690821     0.6473004695     172.2778959274  

========ROUND 24========
====Feature update====
epoch            class_loss      
0                0.2414599210    
1                0.2160803527    
2                0.2171198875    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2628071308     0.9455018640     0.3173052669    
1                1.3834669590     1.0377031565     0.3457638323    
2                1.1441128254     1.0160843134     0.1280284524    
Counter({7: 790, 1: 517, 4: 436, 8: 408, 2: 399, 3: 348, 5: 342, 0: 330, 6: 319, 9: 255})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2097548246     1.2655465603     1.4753013849     0.9621138996     0.7719806763     0.6543427230     56.0421509743   
1                0.1123293117     1.3435145617     1.4558439255     0.9693532819     0.7835748792     0.6473004695     113.0144739151  
2                0.2174876034     1.4860540628     1.7035416365     0.9792471042     0.7932367150     0.6549295775     169.8240449429  

========ROUND 25========
====Feature update====
epoch            class_loss      
0                0.3542941809    
1                0.1693836451    
2                0.2438991666    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4470586777     1.1572710276     0.2897876203    
1                1.3068995476     1.1563535929     0.1505459696    
2                1.1083521843     0.9085200429     0.1998321116    
Counter({7: 792, 1: 514, 4: 447, 8: 405, 2: 394, 3: 347, 5: 342, 0: 325, 6: 317, 9: 261})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1555384696     1.5183604956     1.6738989353     0.9857625483     0.7961352657     0.6584507042     54.2344560623   
1                0.1276479214     1.3432097435     1.4708576202     0.9758687259     0.7729468599     0.6291079812     110.3983418941  
2                0.1202710494     1.4405511618     1.5608222485     0.9650096525     0.7739130435     0.6384976526     165.4082071781  

========ROUND 26========
====Feature update====
epoch            class_loss      
0                0.1921097636    
1                0.2606454790    
2                0.1230023727    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.1662185192     1.0444976091     0.1217209250    
1                0.9939678311     0.8990430832     0.0949247405    
2                1.5217832327     1.1799874306     0.3417958319    
Counter({7: 806, 1: 547, 4: 431, 2: 383, 8: 376, 5: 351, 3: 349, 6: 334, 0: 317, 9: 250})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1214085668     1.5665081739     1.6879167557     0.9782818533     0.7951690821     0.6367370892     54.4849221706   
1                0.0705038309     1.3465023041     1.4170061350     0.9775579151     0.7787439614     0.6408450704     108.1775789261  
2                0.1773341894     1.4838069677     1.6611411572     0.9401544402     0.7526570048     0.6185446009     162.7254951000  

========ROUND 27========
====Feature update====
epoch            class_loss      
0                0.2760525942    
1                0.1454257667    
2                0.1960997134    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4946768284     0.9537634254     0.5409134030    
1                1.4774959087     1.1993032694     0.2781925797    
2                1.4127300978     1.1988798380     0.2138502896    
Counter({7: 770, 1: 556, 4: 470, 8: 381, 2: 375, 3: 348, 5: 346, 6: 323, 0: 322, 9: 253})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1321385354     1.2802555561     1.4123940468     0.9638030888     0.7826086957     0.6672535211     63.3252620697   
1                0.1055516303     1.8807566166     1.9863082170     0.8904440154     0.6888888889     0.5933098592     115.9694809914  
2                0.1235635802     1.4866689444     1.6102324724     0.9693532819     0.7729468599     0.6296948357     166.2841730118  

========ROUND 28========
====Feature update====
epoch            class_loss      
0                0.3110087514    
1                0.2955170274    
2                0.1700250506    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3857915401     1.0055069923     0.3802845180    
1                1.2810646296     1.0675644875     0.2135001421    
2                1.2501807213     1.1081929207     0.1419878453    
Counter({7: 785, 1: 579, 4: 437, 8: 383, 2: 370, 3: 349, 5: 348, 6: 327, 0: 317, 9: 249})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1257272214     1.5717759132     1.6975030899     0.9761100386     0.7816425121     0.6502347418     43.1998510361   
1                0.1032479927     1.3327705860     1.4360185862     0.9802123552     0.7787439614     0.6490610329     88.7245700359   
2                0.1510055512     1.6449357271     1.7959412336     0.9792471042     0.7816425121     0.6390845070     139.3154370785  

========ROUND 29========
====Feature update====
epoch            class_loss      
0                0.2329324931    
1                0.1258529127    
2                0.2303002179    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4921488762     1.1380161047     0.3541328311    
1                1.3417568207     1.1523880959     0.1893686950    
2                1.5064222813     1.2955683470     0.2108539194    
Counter({7: 852, 1: 545, 4: 436, 8: 393, 2: 372, 3: 345, 5: 337, 0: 314, 6: 309, 9: 241})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1741627008     1.4857957363     1.6599584818     0.9886583012     0.7806763285     0.6561032864     43.5500428677   
1                0.0832448900     1.5132297277     1.5964746475     0.9852799228     0.7768115942     0.6484741784     87.6867120266   
2                0.1341899037     1.5098099709     1.6439998150     0.9695945946     0.7574879227     0.6302816901     130.6875550747  

========ROUND 30========
====Feature update====
epoch            class_loss      
0                0.3143738508    
1                0.2102254927    
2                0.2176788747    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4053213596     1.1699070930     0.2354142666    
1                1.2859575748     1.0877853632     0.1981722713    
2                1.4520354271     1.2341414690     0.2178940177    
Counter({7: 811, 1: 586, 4: 450, 2: 385, 8: 384, 3: 340, 5: 329, 0: 316, 6: 306, 9: 237})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0686178505     1.6862689257     1.7548867464     0.9708011583     0.7777777778     0.6426056338     41.3704180717   
1                0.1146506220     1.5266566277     1.6413072348     0.9888996139     0.7961352657     0.6478873239     83.7546031475   
2                0.2196123898     1.5256741047     1.7452864647     0.9802123552     0.7690821256     0.6531690141     123.7303471565  

========ROUND 31========
====Feature update====
epoch            class_loss      
0                0.4907478094    
1                0.2176508009    
2                0.1962382048    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.2513200045     1.0163156986     0.2350043207    
1                1.1301659346     0.9605728984     0.1695930362    
2                1.5936902761     1.4494178295     0.1442724466    
Counter({7: 762, 1: 552, 4: 500, 8: 429, 2: 387, 3: 347, 0: 317, 5: 311, 6: 301, 9: 238})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1934387088     1.5692907572     1.7627294064     0.9695945946     0.7806763285     0.6390845070     48.3883669376   
1                0.1089508757     1.5894856453     1.6984364986     0.9879343629     0.7913043478     0.6549295775     98.6105451584   
2                0.1529285014     1.5193258524     1.6722543240     0.9881756757     0.7874396135     0.6443661972     137.7759768963  

========ROUND 32========
====Feature update====
epoch            class_loss      
0                0.4808551967    
1                0.1857385486    
2                0.1490586400    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3029088974     1.0148969889     0.2880119085    
1                1.4335168600     1.2491590977     0.1843577325    
2                1.4891227484     1.3035743237     0.1855484545    
Counter({4: 1087, 1: 609, 8: 461, 2: 380, 3: 342, 6: 327, 0: 313, 5: 302, 9: 249, 7: 74})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1319576055     1.5051984787     1.6371561289     0.9816602317     0.8086956522     0.6602112676     35.9145109653   
1                0.0811662823     1.6799802780     1.7611465454     0.9736969112     0.7951690821     0.6484741784     72.5732970238   
2                0.0995518565     1.5814766884     1.6810286045     0.9860038610     0.7922705314     0.6490610329     104.8508660793  

========ROUND 33========
====Feature update====
epoch            class_loss      
0                0.2898730636    
1                0.2070305943    
2                0.2526047528    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.5056531429     1.1938843727     0.3117688000    
1                1.1391887665     0.8778045177     0.2613843083    
2                1.7081207037     1.3590590954     0.3490616083    
Counter({4: 1136, 1: 614, 8: 430, 2: 360, 3: 334, 6: 334, 0: 306, 5: 305, 9: 251, 7: 74})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0820689350     1.6257380247     1.7078069448     0.9850386100     0.7942028986     0.6555164319     39.9359879494   
1                0.1385367513     1.4576621056     1.5961987972     0.9657335907     0.7690821256     0.6343896714     85.3127679825   
2                0.1229091361     1.8899569511     2.0128660202     0.9835907336     0.7855072464     0.6343896714     124.6828629971  

========ROUND 34========
====Feature update====
epoch            class_loss      
0                0.3514733613    
1                0.2199957967    
2                0.1622756273    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.5370514393     1.2796940804     0.2573573589    
1                1.7099885941     1.3353048563     0.3746837378    
2                1.3566572666     1.2025315762     0.1541256607    
Counter({4: 1032, 1: 621, 8: 500, 2: 364, 3: 335, 6: 314, 5: 307, 0: 307, 9: 270, 7: 94})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0989461914     1.5283720493     1.6273182631     0.9777992278     0.8077294686     0.6684272300     45.8658390045   
1                0.0707681403     1.4989964962     1.5697646141     0.9843146718     0.7932367150     0.6666666667     91.8715651035   
2                0.1646052152     1.7950657606     1.9596710205     0.9872104247     0.7932367150     0.6490610329     144.6149828434  

========ROUND 35========
====Feature update====
epoch            class_loss      
0                0.3913545012    
1                0.2845693827    
2                0.1347335577    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4881260395     1.1768277884     0.3112982810    
1                1.3067336082     1.1289430857     0.1777904630    
2                1.1430476904     1.0029201508     0.1401275694    
Counter({4: 1009, 1: 633, 8: 513, 2: 365, 3: 341, 5: 305, 6: 305, 0: 305, 9: 259, 7: 109})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0934433639     1.5343554020     1.6277987957     0.9893822394     0.8096618357     0.6514084507     52.1848070621   
1                0.2695394754     1.8123192787     2.0818586349     0.9891409266     0.7826086957     0.6525821596     107.1267240047  
2                0.1614978015     1.6367189884     1.7982168198     0.9681467181     0.7826086957     0.6408450704     161.0035309792  

========ROUND 36========
====Feature update====
epoch            class_loss      
0                0.3191004992    
1                0.1923796833    
2                0.1796514541    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3290801048     1.1512352228     0.1778448671    
1                1.4759144783     1.3266006708     0.1493137479    
2                1.1708898544     0.9902526140     0.1806372553    
Counter({4: 1015, 1: 602, 8: 520, 2: 361, 3: 344, 0: 313, 5: 309, 6: 299, 9: 255, 7: 126})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0530339330     1.7779097557     1.8309437037     0.8716216216     0.6840579710     0.5287558685     39.6863212585   
1                0.0828831494     1.5682371855     1.6511203051     0.9860038610     0.8106280193     0.6555164319     80.6674449444   
2                0.1078355461     1.6064430475     1.7142785788     0.9739382239     0.7942028986     0.6308685446     123.0321452618  

========ROUND 37========
====Feature update====
epoch            class_loss      
0                0.3482873738    
1                0.1502094716    
2                0.2029170394    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3929796219     1.1046615839     0.2883180380    
1                1.1576242447     1.0002722740     0.1573519111    
2                1.7645465136     1.4362075329     0.3283389509    
Counter({4: 988, 1: 631, 8: 504, 2: 357, 3: 354, 0: 312, 5: 300, 6: 285, 9: 251, 7: 162})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1325455159     1.4996222258     1.6321676970     0.9867277992     0.7971014493     0.6408450704     46.6000800133   
1                0.0632796809     1.4196758270     1.4829554558     0.9860038610     0.7951690821     0.6484741784     100.0327811241  
2                0.0439176261     1.6235629320     1.6674805880     0.9695945946     0.7777777778     0.6308685446     150.2551600933  

========ROUND 38========
====Feature update====
epoch            class_loss      
0                0.2746657729    
1                0.2472494692    
2                0.0969492048    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3785467148     1.1005759239     0.2779707909    
1                1.5323947668     1.3258097172     0.2065850645    
2                1.3371616602     1.1704027653     0.1667589396    
Counter({4: 1050, 1: 615, 8: 472, 2: 346, 3: 343, 6: 320, 0: 306, 5: 294, 9: 236, 7: 162})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0739832297     1.6008948088     1.6748780012     0.9884169884     0.8048309179     0.6467136150     36.4059667587   
1                0.0540570691     1.5083413124     1.5623984337     0.9903474903     0.8009661836     0.6578638498     78.0251758099   
2                0.1009224355     1.4468574524     1.5477799177     0.9799710425     0.7942028986     0.6437793427     123.4923210144  

========ROUND 39========
====Feature update====
epoch            class_loss      
0                0.2298540473    
1                0.2088633329    
2                0.1630359292    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.5203685760     1.3151574135     0.2052111328    
1                1.4641402960     1.3205872774     0.1435529739    
2                1.2451372147     1.1539472342     0.0911900103    
Counter({4: 1046, 1: 586, 8: 524, 3: 350, 2: 347, 0: 303, 5: 298, 6: 298, 9: 244, 7: 148})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0584478304     1.6309386492     1.6893864870     0.9773166023     0.7942028986     0.6396713615     38.0018970966   
1                0.1983642429     1.6294877529     1.8278520107     0.9546332046     0.7458937198     0.6185446009     84.2162811756   
2                0.0541916527     1.4697033167     1.5238950253     0.9920366795     0.8048309179     0.6666666667     129.0327601433  

========ROUND 40========
====Feature update====
epoch            class_loss      
0                0.3309084177    
1                0.1452962309    
2                0.2399504185    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.5515091419     1.1649446487     0.3865644634    
1                1.2696020603     1.1343995333     0.1352024674    
2                1.4211393595     1.3058228493     0.1153164729    
Counter({4: 992, 1: 629, 8: 523, 3: 356, 2: 340, 5: 299, 6: 297, 0: 294, 9: 266, 7: 148})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1564123780     1.6283186674     1.7847310305     0.9843146718     0.7942028986     0.6426056338     43.5191299915   
1                0.1164080277     1.6058284044     1.7222363949     0.9901061776     0.8019323671     0.6590375587     97.8558759689   
2                0.0923700556     1.7258405685     1.8182106018     0.9891409266     0.7845410628     0.6543427230     152.4937641621  

========ROUND 41========
====Feature update====
epoch            class_loss      
0                0.3563641012    
1                0.1789511740    
2                0.1720373929    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.6816018820     1.3067249060     0.3748769760    
1                1.5013926029     1.3541324139     0.1472602040    
2                1.4168893099     1.2899525166     0.1269368380    
Counter({4: 1002, 1: 622, 8: 535, 3: 349, 2: 326, 0: 297, 6: 297, 5: 293, 9: 263, 7: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1498787403     1.4990289211     1.6489076614     0.9913127413     0.8193236715     0.6543427230     45.0359969139   
1                0.0710835382     1.6583576202     1.7294411659     0.9920366795     0.8000000000     0.6484741784     95.4856281281   
2                0.0465841815     1.5240063667     1.5705904961     0.9879343629     0.8019323671     0.6496478873     127.8902020454  

========ROUND 42========
====Feature update====
epoch            class_loss      
0                0.2592752576    
1                0.2070540786    
2                0.1576510668    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3261404037     1.2059038877     0.1202365533    
1                1.4261308908     1.2607007027     0.1654302031    
2                1.3650712967     1.2471820116     0.1178892329    
Counter({4: 1019, 1: 606, 8: 531, 3: 346, 2: 323, 6: 302, 0: 298, 5: 294, 9: 265, 7: 160})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0757587254     1.6173484325     1.6931071281     0.9876930502     0.7893719807     0.6431924883     35.4646451473   
1                0.0828177705     1.7251448631     1.8079626560     0.9884169884     0.7806763285     0.6525821596     71.8415031433   
2                0.0530015007     1.6563214064     1.7093229294     0.9799710425     0.7777777778     0.6267605634     109.0793652534  

========ROUND 43========
====Feature update====
epoch            class_loss      
0                0.3480380177    
1                0.0853445232    
2                0.1176940203    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.7282552719     1.4035176039     0.3247376382    
1                1.4065153599     1.2360657454     0.1704495549    
2                1.5990852118     1.4063823223     0.1927028894    
Counter({4: 1025, 1: 617, 8: 524, 3: 347, 2: 312, 6: 302, 0: 297, 5: 290, 9: 260, 7: 170})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0885526538     1.7726585865     1.8612112999     0.9852799228     0.8009661836     0.6643192488     37.4159049988   
1                0.0357603505     1.6569640636     1.6927244663     0.9910714286     0.8048309179     0.6473004695     75.9444110394   
2                0.1161720082     1.5903592110     1.7065311670     0.9939671815     0.8057971014     0.6514084507     110.6478149891  

========ROUND 44========
====Feature update====
epoch            class_loss      
0                0.3485715389    
1                0.1521467119    
2                0.1769322306    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4641460180     1.2405794859     0.2235665321    
1                1.5497132540     1.3794322014     0.1702810079    
2                1.2448220253     1.1783142090     0.0665078163    
Counter({4: 959, 1: 608, 8: 563, 3: 345, 6: 313, 2: 308, 5: 299, 0: 298, 9: 284, 7: 167})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.2655482590     1.5795365572     1.8450847864     0.9903474903     0.8086956522     0.6584507042     40.5719320774   
1                0.1271201074     1.6081351042     1.7352552414     0.9879343629     0.7729468599     0.6379107981     73.2997920513   
2                0.1134941429     1.3952658176     1.5087599754     0.9944498069     0.8057971014     0.6443661972     107.5060980320  

========ROUND 45========
====Feature update====
epoch            class_loss      
0                0.4128118753    
1                0.2095949054    
2                0.2157477736    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.6591802835     1.2833220959     0.3758582175    
1                1.3808541298     1.1687511206     0.2121029496    
2                1.3545923233     1.2078700066     0.1467222571    
Counter({4: 960, 1: 605, 8: 543, 3: 349, 6: 311, 2: 307, 0: 305, 5: 300, 9: 288, 7: 176})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0912188813     1.5627070665     1.6539258957     0.9840733591     0.8038647343     0.6408450704     36.3987829685   
1                0.0343313366     1.6437017918     1.6780331135     0.9930019305     0.7980676329     0.6355633803     74.5771267414   
2                0.1030785143     1.6770588160     1.7801373005     0.9869691120     0.8009661836     0.6437793427     108.6073017120  

========ROUND 46========
====Feature update====
epoch            class_loss      
0                0.3330023587    
1                0.0551558286    
2                0.1611227393    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3457849026     1.1232417822     0.2225430757    
1                1.1957547665     1.0329630375     0.1627917588    
2                1.6611667871     1.5081316233     0.1530351490    
Counter({4: 936, 1: 617, 8: 525, 3: 347, 6: 320, 2: 305, 0: 304, 9: 303, 5: 297, 7: 190})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.1498087049     1.4300080538     1.5798168182     0.9872104247     0.8115942029     0.6619718310     32.6291160583   
1                0.0991275609     1.7386137247     1.8377412558     0.9867277992     0.8009661836     0.6566901408     66.3476960659   
2                0.0659292638     1.8165781498     1.8825074434     0.9845559846     0.7961352657     0.6508215962     100.1216371059  

========ROUND 47========
====Feature update====
epoch            class_loss      
0                0.1896229386    
1                0.1373222172    
2                0.1396705508    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.4866453409     1.2069840431     0.2796612680    
1                1.4356546402     1.2433172464     0.1923373491    
2                1.4570630789     1.3101472855     0.1469158083    
Counter({4: 931, 1: 618, 8: 529, 3: 346, 6: 318, 0: 307, 5: 304, 2: 301, 9: 295, 7: 195})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0516896099     1.5643179417     1.6160075665     0.9891409266     0.8019323671     0.6637323944     33.8414108753   
1                0.0661810264     1.6297097206     1.6958907843     0.9855212355     0.7864734300     0.6279342723     66.8176157475   
2                0.1569522470     1.6439757347     1.8009279966     0.9891409266     0.7806763285     0.6502347418     100.6280548573  

========ROUND 48========
====Feature update====
epoch            class_loss      
0                0.2961964011    
1                0.1928609163    
2                0.1682837903    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3585680723     1.2226198912     0.1359481364    
1                1.4797387123     1.2883913517     0.1913473010    
2                1.3905062675     1.2287497520     0.1617565751    
Counter({4: 938, 1: 617, 8: 531, 3: 353, 6: 318, 5: 302, 0: 299, 9: 297, 2: 296, 7: 193})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0704904422     1.6310220957     1.7015125751     0.9852799228     0.7932367150     0.6443661972     32.1982541084   
1                0.0636848509     1.6401224136     1.7038072348     0.9963803089     0.8057971014     0.6455399061     66.1672089100   
2                0.1040178463     1.6881643534     1.7921822071     0.9951737452     0.7768115942     0.6508215962     98.1502771378   

========ROUND 49========
====Feature update====
epoch            class_loss      
0                0.2878910899    
1                0.1768593192    
2                0.1705473512    
====Latent domain characterization====
epoch            total_loss       dis_loss         ent_loss        
0                1.3744590282     1.1496747732     0.2247842103    
1                1.8414855003     1.4489089251     0.3925765157    
2                1.3323068619     1.1977372169     0.1345696747    
Counter({4: 926, 1: 623, 8: 522, 3: 351, 6: 322, 5: 302, 9: 299, 2: 296, 0: 295, 7: 208})
====Domain-invariant feature learning====
epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time 
0                0.0740001798     1.6085063219     1.6825065613     0.9872104247     0.7884057971     0.6449530516     51.6117589474   
1                0.0749738514     1.7881423235     1.8631161451     0.9886583012     0.7826086957     0.6537558685     94.4843568802   
2                0.0623583272     1.8371134996     1.8994718790     0.9917953668     0.7758454106     0.6414319249     131.2849869728  
Target acc: 0.7066
